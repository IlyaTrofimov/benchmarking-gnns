{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Driver Notebook for Training Graph NNs on TU Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "- GatedGCN \n",
    "- GCN \n",
    "- GAT \n",
    "- GraphSage \n",
    "- GIN  \n",
    "- MoNet  \n",
    "- MLP  \n",
    "- RingGNN  \n",
    "- 3WLGNN   \n",
    "\n",
    "### DATASET\n",
    "- DD \n",
    "- ENZYMES\n",
    "- PROTEINS_full   \n",
    "\n",
    "### TASK\n",
    "- Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    IMPORTING LIBS\n",
    "\"\"\"\n",
    "import dgl\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import argparse, json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "#     AUTORELOAD IPYTHON EXTENSION FOR RELOADING IMPORTED MODULES\n",
    "# \"\"\"\n",
    "\n",
    "def in_ipynb():\n",
    "    try:\n",
    "        cfg = get_ipython().config \n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "    \n",
    "notebook_mode = in_ipynb()\n",
    "print(notebook_mode)\n",
    "\n",
    "if notebook_mode == True:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    IMPORTING CUSTOM MODULES/METHODS\n",
    "\"\"\"\n",
    "\n",
    "from nets.TUs_graph_classification.load_net import gnn_model # import GNNs\n",
    "from data.data import LoadData # import dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    GPU Setup\n",
    "\"\"\"\n",
    "def gpu_setup(use_gpu, gpu_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print('cuda not available')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "\n",
    "# select GPU or CPU\n",
    "#use_gpu = True; gpu_id = 0; device = None # default GPU\n",
    "use_gpu = False; gpu_id = -1; device = None # CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading data (notebook) ...\n",
      "[!] Dataset:  ENZYMES\n",
      "Time taken: 0.5786s\n",
      "[I] Finished loading.\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "#     USER CONTROLS\n",
    "# \"\"\"\n",
    "if notebook_mode == True:\n",
    "    \n",
    "    #MODEL_NAME = '3WLGNN'\n",
    "    #MODEL_NAME = 'RingGNN'\n",
    "    #MODEL_NAME = 'GatedGCN'\n",
    "    #MODEL_NAME = 'MoNet'\n",
    "    #MODEL_NAME = 'GCN'\n",
    "    MODEL_NAME = 'GATTop'\n",
    "    #MODEL_NAME = 'GraphSage'\n",
    "    #MODEL_NAME = 'GIN'\n",
    "    #MODEL_NAME = 'MLP'\n",
    "\n",
    "    DATASET_NAME = 'ENZYMES'\n",
    "    #DATASET_NAME = 'PROTEINS_full'\n",
    "    #DATASET_NAME = 'DD'\n",
    "\n",
    "    out_dir = 'out/TUs_graph_classification/'\n",
    "    root_log_dir = out_dir + 'logs/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "    root_ckpt_dir = out_dir + 'checkpoints/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "\n",
    "    print(\"[I] Loading data (notebook) ...\")\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "    print(\"[I] Finished loading.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True hidden dim: 144\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "#     PARAMETERS\n",
    "# \"\"\"\n",
    "if notebook_mode == True:\n",
    "\n",
    "    n_heads = -1\n",
    "    edge_feat = False\n",
    "    pseudo_dim_MoNet = -1\n",
    "    kernel = -1\n",
    "    gnn_per_block = -1\n",
    "    embedding_dim = -1\n",
    "    pool_ratio = -1\n",
    "    n_mlp_GIN = -1\n",
    "    gated = False\n",
    "    self_loop = False\n",
    "    #self_loop = True\n",
    "    max_time = 120\n",
    "    \n",
    "    if MODEL_NAME == 'GatedGCN':\n",
    "        seed=41; epochs=1000; batch_size=5; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; hidden_dim=70; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "\n",
    "    if MODEL_NAME == 'GCN':\n",
    "        seed=41; epochs=1000; batch_size=5; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; hidden_dim=146; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "\n",
    "    if MODEL_NAME == 'GAT':\n",
    "        #seed=41; epochs=1000; batch_size=50; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        #L=4; n_heads=8; hidden_dim=19; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'\n",
    "        #print('True hidden dim:',out_dim)\n",
    "        \n",
    "        seed=41; epochs=1000; batch_size=20; init_lr=1e-3; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; n_heads=8; hidden_dim=18; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'\n",
    "        print('True hidden dim:',out_dim)\n",
    "        \n",
    "    if MODEL_NAME == 'GATTop':\n",
    "        #seed=41; epochs=1000; batch_size=50; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        #L=4; n_heads=8; hidden_dim=19; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'\n",
    "        #print('True hidden dim:',out_dim)\n",
    "        \n",
    "        seed=41; epochs=1000; batch_size=20; init_lr=1e-3; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; n_heads=8; hidden_dim=18; out_dim=n_heads*hidden_dim; dropout=0.0; readout='mean'\n",
    "        print('True hidden dim:',out_dim)\n",
    "\n",
    "    if MODEL_NAME == 'GraphSage':\n",
    "        seed=41; epochs=1000; batch_size=50; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; hidden_dim=108; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "\n",
    "    if MODEL_NAME == 'MLP':\n",
    "        seed=41; epochs=1000; batch_size=50; init_lr=5e-4; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; hidden_dim=165; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "        \n",
    "    if MODEL_NAME == 'DiffPool':\n",
    "        seed=41; epochs=1000; batch_size=50; init_lr=5e-4; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; hidden_dim=32; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "        n_heads=8; gnn_per_block=3; embedding_dim=32; batch_size=128; pool_ratio=0.15\n",
    "\n",
    "    if MODEL_NAME == 'GIN':\n",
    "        seed=41; epochs=1000; batch_size=50; init_lr=5e-4; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; hidden_dim=110; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "        n_mlp_GIN = 2; learn_eps_GIN=True; neighbor_aggr_GIN='sum'\n",
    "\n",
    "    if MODEL_NAME == 'MoNet':\n",
    "        seed=41; epochs=1000; batch_size=50; init_lr=5e-4; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        L=4; hidden_dim=90; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "        pseudo_dim_MoNet=2; kernel=3;\n",
    "      \n",
    "    if MODEL_NAME == 'RingGNN':\n",
    "        seed=41; epochs=1000; batch_size=1; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        #L=4; hidden_dim=145; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "        L=4; hidden_dim=22; out_dim=hidden_dim; dropout=0.0;\n",
    "    \n",
    "    if MODEL_NAME == '3WLGNN':\n",
    "        seed=41; epochs=1000; batch_size=1; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
    "        #L=4; hidden_dim=145; out_dim=hidden_dim; dropout=0.0; readout='mean'\n",
    "        L=3; hidden_dim=76; out_dim=hidden_dim; dropout=0.0;\n",
    "    \n",
    "\n",
    "    # generic new_params\n",
    "    net_params = {}\n",
    "    net_params['device'] = device\n",
    "    net_params['gated'] = False  # for mlpnet baseline\n",
    "    net_params['in_dim'] = dataset.all.graph_lists[0].ndata['feat'][0].shape[0]\n",
    "    net_params['residual'] = True\n",
    "    net_params['hidden_dim'] = hidden_dim\n",
    "    net_params['out_dim'] = out_dim\n",
    "    num_classes = len(np.unique(dataset.all.graph_labels))\n",
    "    net_params['n_classes'] = num_classes\n",
    "    net_params['n_heads'] = n_heads\n",
    "    net_params['L'] = L  # min L should be 2\n",
    "    net_params['readout'] = \"mean\"\n",
    "    net_params['layer_norm'] = True\n",
    "    net_params['batch_norm'] = True\n",
    "    net_params['in_feat_dropout'] = 0.0\n",
    "    net_params['dropout'] = 0.0\n",
    "    net_params['edge_feat'] = edge_feat\n",
    "    net_params['self_loop'] = self_loop\n",
    "\n",
    "    # specific for MoNet\n",
    "    net_params['pseudo_dim_MoNet'] = pseudo_dim_MoNet\n",
    "    net_params['kernel'] = kernel\n",
    "    \n",
    "    # specific for GIN\n",
    "    net_params['n_mlp_GIN'] = n_mlp_GIN\n",
    "    net_params['learn_eps_GIN'] = True\n",
    "    net_params['neighbor_aggr_GIN'] = 'sum'\n",
    "    \n",
    "    # specific for graphsage\n",
    "    net_params['sage_aggregator'] = 'meanpool'    \n",
    "\n",
    "    # specific for diffpoolnet\n",
    "    net_params['data_mode'] = 'default'\n",
    "    net_params['gnn_per_block'] = gnn_per_block\n",
    "    net_params['embedding_dim'] = embedding_dim     \n",
    "    net_params['pool_ratio'] = pool_ratio\n",
    "    net_params['linkpred'] = True\n",
    "    net_params['num_pool'] = 1\n",
    "    net_params['cat'] = False\n",
    "    net_params['batch_size'] = batch_size \n",
    "    \n",
    "    # specific for RingGNN\n",
    "    net_params['radius'] = 2\n",
    "    num_nodes = [dataset.all[i][0].number_of_nodes() for i in range(len(dataset.all))]\n",
    "    net_params['avg_node_num'] = int(np.ceil(np.mean(num_nodes)))\n",
    "    \n",
    "    # specific for 3WLGNN\n",
    "    net_params['depth_of_mlp'] = 2\n",
    "    \n",
    "    # calculate assignment dimension: pool_ratio * largest graph's maximum\n",
    "    # number of nodes  in the dataset\n",
    "    max_num_node = max(num_nodes)\n",
    "    net_params['assign_dim'] = int(max_num_node * net_params['pool_ratio']) * net_params['batch_size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL DETAILS:\n",
      "\n",
      "MODEL/Total parameters: GATTop 101922\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    VIEWING MODEL CONFIG AND PARAMS\n",
    "\"\"\"\n",
    "def view_model_param(MODEL_NAME, net_params):\n",
    "    model = gnn_model(MODEL_NAME, net_params)\n",
    "    total_param = 0\n",
    "    print(\"MODEL DETAILS:\\n\")\n",
    "    #print(model)\n",
    "    for param in model.parameters():\n",
    "        # print(param.data.size())\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print('MODEL/Total parameters:', MODEL_NAME, total_param)\n",
    "    return total_param\n",
    "\n",
    "if notebook_mode == True:\n",
    "    view_model_param(MODEL_NAME, net_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    TRAINING CODE\n",
    "\"\"\"\n",
    "\n",
    "def train_val_pipeline(MODEL_NAME, DATASET_NAME, params, net_params, dirs):\n",
    "    avg_test_acc = []\n",
    "    avg_train_acc = []\n",
    "    avg_convergence_epochs = []\n",
    "\n",
    "    t0 = time.time()\n",
    "    per_epoch_time = []\n",
    "\n",
    "    dataset = LoadData(DATASET_NAME)\n",
    "    \n",
    "    if MODEL_NAME in ['GCN', 'GAT', 'GATTop']:\n",
    "        if net_params['self_loop']:\n",
    "            print(\"[!] Adding graph self-loops for GCN/GAT models (central node trick).\")\n",
    "            dataset._add_self_loops()\n",
    "    \n",
    "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "    \n",
    "    root_log_dir, root_ckpt_dir, write_file_name, write_config_file = dirs\n",
    "    device = net_params['device']\n",
    "    \n",
    "    # Write the network and optimization hyper-parameters in folder config/\n",
    "    with open(write_config_file + '.txt', 'w') as f:\n",
    "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n\\nTotal Parameters: {}\\n\\n\"\"\"\\\n",
    "                .format(DATASET_NAME, MODEL_NAME, params, net_params, net_params['total_param']))\n",
    "    \n",
    "    # At any point you can hit Ctrl + C to break out of training early.\n",
    "    try:\n",
    "        for split_number in range(10):\n",
    "            t0_split = time.time()\n",
    "            log_dir = os.path.join(root_log_dir, \"RUN_\" + str(split_number))\n",
    "            writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "            # setting seeds\n",
    "            random.seed(params['seed'])\n",
    "            np.random.seed(params['seed'])\n",
    "            torch.manual_seed(params['seed'])\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.manual_seed(params['seed'])\n",
    "\n",
    "            print(\"RUN NUMBER: \", split_number)\n",
    "            trainset, valset, testset = dataset.train[split_number], dataset.val[split_number], dataset.test[split_number]\n",
    "            print(\"Training Graphs: \", len(trainset))\n",
    "            print(\"Validation Graphs: \", len(valset))\n",
    "            print(\"Test Graphs: \", len(testset))\n",
    "            print(\"Number of Classes: \", net_params['n_classes'])\n",
    "\n",
    "            model = gnn_model(MODEL_NAME, net_params)\n",
    "            \n",
    "            print(model.h0_sum)\n",
    "            print(model.top_feat_active)\n",
    "            \n",
    "            model = model.to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=params['init_lr'], weight_decay=params['weight_decay'])\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                             factor=params['lr_reduce_factor'],\n",
    "                                                             patience=params['lr_schedule_patience'],\n",
    "                                                             verbose=True)\n",
    "\n",
    "            epoch_train_losses, epoch_val_losses = [], []\n",
    "            epoch_train_accs, epoch_val_accs = [], [] \n",
    "\n",
    "            # batching exception for Diffpool\n",
    "            drop_last = True if MODEL_NAME == 'DiffPool' else False\n",
    "\n",
    "            if MODEL_NAME in ['RingGNN', '3WLGNN']:\n",
    "                # import train functions specific for WL-GNNs\n",
    "                from train.train_TUs_graph_classification import train_epoch_dense as train_epoch, evaluate_network_dense as evaluate_network\n",
    "\n",
    "                train_loader = DataLoader(trainset, shuffle=True, collate_fn=dataset.collate_dense_gnn)\n",
    "                val_loader = DataLoader(valset, shuffle=False, collate_fn=dataset.collate_dense_gnn)\n",
    "                test_loader = DataLoader(testset, shuffle=False, collate_fn=dataset.collate_dense_gnn)\n",
    "\n",
    "            else:\n",
    "                # import train functions for all other GCNs\n",
    "                from train.train_TUs_graph_classification import train_epoch_sparse as train_epoch, evaluate_network_sparse as evaluate_network\n",
    "\n",
    "                train_loader = DataLoader(trainset, batch_size=params['batch_size'], shuffle=True, drop_last=drop_last, collate_fn=dataset.collate)\n",
    "                val_loader = DataLoader(valset, batch_size=params['batch_size'], shuffle=False, drop_last=drop_last, collate_fn=dataset.collate)\n",
    "                test_loader = DataLoader(testset, batch_size=params['batch_size'], shuffle=False, drop_last=drop_last, collate_fn=dataset.collate)\n",
    "  \n",
    "            with tqdm(range(params['epochs'])) as t:\n",
    "                for epoch in t:\n",
    "\n",
    "                    t.set_description('Epoch %d' % epoch)\n",
    "                    \n",
    "                    if epoch < 100:\n",
    "                        model.top_feat_active = 0.0\n",
    "                    else:\n",
    "                        model.top_feat_active = 1.0\n",
    "\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    #with torch.autograd.set_detect_anomaly(True):\n",
    "                    if MODEL_NAME in ['RingGNN', '3WLGNN']: # since different batch training function for dense GNNs\n",
    "                        epoch_train_loss, epoch_train_acc, optimizer = train_epoch(model, optimizer, device, train_loader, epoch, params['batch_size'])\n",
    "                    else:   # for all other models common train function\n",
    "                        epoch_train_loss, epoch_train_acc, optimizer = train_epoch(model, optimizer, device, train_loader, epoch)\n",
    "\n",
    "                    epoch_val_loss, epoch_val_acc = evaluate_network(model, device, val_loader, epoch)\n",
    "                    _, epoch_test_acc = evaluate_network(model, device, test_loader, epoch)\n",
    "\n",
    "                    epoch_train_losses.append(epoch_train_loss)\n",
    "                    epoch_val_losses.append(epoch_val_loss)\n",
    "                    epoch_train_accs.append(epoch_train_acc)\n",
    "                    epoch_val_accs.append(epoch_val_acc)\n",
    "\n",
    "                    writer.add_scalar('train/_loss', epoch_train_loss, epoch)\n",
    "                    writer.add_scalar('val/_loss', epoch_val_loss, epoch)\n",
    "                    writer.add_scalar('train/_acc', epoch_train_acc, epoch)\n",
    "                    writer.add_scalar('val/_acc', epoch_val_acc, epoch)\n",
    "                    writer.add_scalar('test/_acc', epoch_test_acc, epoch)\n",
    "                    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "                    _, epoch_test_acc = evaluate_network(model, device, test_loader, epoch)\n",
    "                    t.set_postfix(time=time.time()-start, lr=optimizer.param_groups[0]['lr'],\n",
    "                                  train_loss=epoch_train_loss, val_loss=epoch_val_loss,\n",
    "                                  train_acc=epoch_train_acc, val_acc=epoch_val_acc,\n",
    "                                  test_acc=epoch_test_acc)  \n",
    "\n",
    "                    per_epoch_time.append(time.time()-start)\n",
    "\n",
    "                    # Saving checkpoint\n",
    "                    ckpt_dir = os.path.join(root_ckpt_dir, \"RUN_\" + str(split_number))\n",
    "                    if not os.path.exists(ckpt_dir):\n",
    "                        os.makedirs(ckpt_dir)\n",
    "                    torch.save(model.state_dict(), '{}.pkl'.format(ckpt_dir + \"/epoch_\" + str(epoch)))\n",
    "\n",
    "                    files = glob.glob(ckpt_dir + '/*.pkl')\n",
    "                    for file in files:\n",
    "                        epoch_nb = file.split('_')[-1]\n",
    "                        epoch_nb = int(epoch_nb.split('.')[0])\n",
    "                        if epoch_nb < epoch-1:\n",
    "                            os.remove(file)\n",
    "\n",
    "                    scheduler.step(epoch_val_loss)\n",
    "\n",
    "                    if optimizer.param_groups[0]['lr'] < params['min_lr']:\n",
    "                        print(\"\\n!! LR EQUAL TO MIN LR SET.\")\n",
    "                        break\n",
    "                        \n",
    "                    # Stop training after params['max_time'] hours\n",
    "                    if time.time()-t0_split > params['max_time']*3600/10:       # Dividing max_time by 10, since there are 10 runs in TUs\n",
    "                        print('-' * 89)\n",
    "                        print(\"Max_time for one train-val-test split experiment elapsed {:.3f} hours, so stopping\".format(params['max_time']/10))\n",
    "                        break\n",
    "\n",
    "            _, test_acc = evaluate_network(model, device, test_loader, epoch)   \n",
    "            _, train_acc = evaluate_network(model, device, train_loader, epoch)    \n",
    "            avg_test_acc.append(test_acc)   \n",
    "            avg_train_acc.append(train_acc)\n",
    "            avg_convergence_epochs.append(epoch)\n",
    "\n",
    "            print(\"Test Accuracy [LAST EPOCH]: {:.4f}\".format(test_acc))\n",
    "            print(\"Train Accuracy [LAST EPOCH]: {:.4f}\".format(train_acc))\n",
    "            print(\"Convergence Time (Epochs): {:.4f}\".format(epoch))\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('-' * 89)\n",
    "        print('Exiting from training early because of KeyboardInterrupt')\n",
    "        \n",
    "    \n",
    "    print(\"TOTAL TIME TAKEN: {:.4f}hrs\".format((time.time()-t0)/3600))\n",
    "    print(\"AVG TIME PER EPOCH: {:.4f}s\".format(np.mean(per_epoch_time)))\n",
    "    print(\"AVG CONVERGENCE Time (Epochs): {:.4f}\".format(np.mean(np.array(avg_convergence_epochs))))\n",
    "    # Final test accuracy value averaged over 10-fold\n",
    "    print(\"\"\"\\n\\n\\nFINAL RESULTS\\n\\nTEST ACCURACY averaged: {:.4f} with s.d. {:.4f}\"\"\"\\\n",
    "          .format(np.mean(np.array(avg_test_acc))*100, np.std(avg_test_acc)*100))\n",
    "    print(\"\\nAll splits Test Accuracies:\\n\", avg_test_acc)\n",
    "    print(\"\"\"\\n\\n\\nFINAL RESULTS\\n\\nTRAIN ACCURACY averaged: {:.4f} with s.d. {:.4f}\"\"\"\\\n",
    "          .format(np.mean(np.array(avg_train_acc))*100, np.std(avg_train_acc)*100))\n",
    "    print(\"\\nAll splits Train Accuracies:\\n\", avg_train_acc)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    \"\"\"\n",
    "        Write the results in out/results folder\n",
    "    \"\"\"\n",
    "    with open(write_file_name + '.txt', 'w') as f:\n",
    "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n{}\\n\\nTotal Parameters: {}\\n\\n\n",
    "    FINAL RESULTS\\nTEST ACCURACY averaged: {:.4f} with s.d. {:.4f}\\nTRAIN ACCURACY averaged: {:.4f} with s.d. {:.4f}\\n\\n\n",
    "    Average Convergence Time (Epochs): {:.4f} with s.d. {:.4f}\\nTotal Time Taken: {:.4f} hrs\\nAverage Time Per Epoch: {:.4f} s\\n\\n\\nAll Splits Test Accuracies: {}\"\"\"\\\n",
    "          .format(DATASET_NAME, MODEL_NAME, params, net_params, model, net_params['total_param'],\n",
    "                  np.mean(np.array(avg_test_acc))*100, np.std(avg_test_acc)*100,\n",
    "                  np.mean(np.array(avg_train_acc))*100, np.std(avg_train_acc)*100,\n",
    "                  np.mean(avg_convergence_epochs), np.std(avg_convergence_epochs),\n",
    "               (time.time()-t0)/3600, np.mean(per_epoch_time), avg_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert main_TUs_graph_classification.ipynb to main_TUs_graph_classification.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook main_TUs_graph_classification.ipynb to script\n",
      "[NbConvertApp] Writing 29814 bytes to main_TUs_graph_classification.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean main_TUs_graph_classification.py\n",
      "Done. \n",
      "[!] Dataset:  ENZYMES\n",
      "Time taken: 0.8533s\n",
      "cuda not available\n",
      "MODEL DETAILS:\n",
      "\n",
      "MODEL/Total parameters: GATTop 101922\n",
      "[!] Dataset:  ENZYMES\n",
      "Time taken: 0.5560s\n",
      "RUN NUMBER:  0\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81:   8%|▍     | 81/1000 [09:26<2:08:40,  8.40s/it, lr=0.001, test_acc=0.55, time=7.66, train_acc=0.94, train_loss=0.192, val_acc=0.567, val_loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00081: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107:  11%| | 107/1000 [12:28<1:26:29,  5.81s/it, lr=0.0005, test_acc=0.65, time=4.53, train_acc=0.998, train_loss=0.0227, val_acc=0.717, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00107: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133:  13%|▏| 133/1000 [15:24<1:57:03,  8.10s/it, lr=0.00025, test_acc=0.65, time=9.36, train_acc=0.998, train_loss=0.0131, val_acc=0.667, val_loss=1.73"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00133: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159:  16%|▍  | 159/1000 [18:50<1:36:16,  6.87s/it, lr=0.000125, test_acc=0.6, time=5.85, train_acc=1, train_loss=0.00656, val_acc=0.683, val_loss=1.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00159: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185:  18%|▎ | 185/1000 [22:27<2:05:28,  9.24s/it, lr=6.25e-5, test_acc=0.6, time=10.3, train_acc=0.998, train_loss=0.00846, val_acc=0.7, val_loss=1.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00185: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 211:  21%|█▋      | 211/1000 [25:53<1:32:40,  7.05s/it, lr=3.13e-5, test_acc=0.6, time=5.6, train_acc=1, train_loss=0.0059, val_acc=0.7, val_loss=1.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00211: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 237:  24%|▏| 237/1000 [29:39<2:26:55, 11.55s/it, lr=1.56e-5, test_acc=0.6, time=14.9, train_acc=0.998, train_loss=0.00729, val_acc=0.717, val_loss=1.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00237: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 263:  26%|██▎      | 263/1000 [33:30<1:42:40,  8.36s/it, lr=7.81e-6, test_acc=0.6, time=9.48, train_acc=1, train_loss=0.008, val_acc=0.7, val_loss=1.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00263: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289:  29%|█▋    | 289/1000 [37:18<2:20:04, 11.82s/it, lr=3.91e-6, test_acc=0.6, time=13.6, train_acc=1, train_loss=0.00403, val_acc=0.7, val_loss=1.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00289: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 314:  31%|█▉    | 314/1000 [41:16<1:30:09,  7.89s/it, lr=1.95e-6, test_acc=0.6, time=11.8, train_acc=1, train_loss=0.00345, val_acc=0.7, val_loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00315: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.6000\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 314.0000\n",
      "RUN NUMBER:  1\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67:   7%|▎    | 67/1000 [10:25<2:26:38,  9.43s/it, lr=0.001, test_acc=0.617, time=9.1, train_acc=0.908, train_loss=0.253, val_acc=0.617, val_loss=1.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00067: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93:   9%|▎  | 93/1000 [13:58<1:37:02,  6.42s/it, lr=0.0005, test_acc=0.733, time=4.94, train_acc=0.996, train_loss=0.054, val_acc=0.683, val_loss=1.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00093: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119:  12%|▍   | 119/1000 [18:04<2:22:11,  9.68s/it, lr=0.00025, test_acc=0.717, time=11.5, train_acc=1, train_loss=0.028, val_acc=0.683, val_loss=1.84]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00119: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145:  14%|▏| 145/1000 [22:04<2:03:35,  8.67s/it, lr=0.000125, test_acc=0.733, time=7.47, train_acc=0.998, train_loss=0.016, val_acc=0.7, val_loss=1.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00145: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171:  17%|█▎      | 171/1000 [26:08<2:21:02, 10.21s/it, lr=6.25e-5, test_acc=0.733, time=11, train_acc=1, train_loss=0.0114, val_acc=0.7, val_loss=1.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00171: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197:  20%|▉    | 197/1000 [30:21<2:13:00,  9.94s/it, lr=3.13e-5, test_acc=0.733, time=12.1, train_acc=1, train_loss=0.0114, val_acc=0.7, val_loss=1.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00197: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 223:  22%|▉   | 223/1000 [34:39<2:09:38, 10.01s/it, lr=1.56e-5, test_acc=0.733, time=11, train_acc=1, train_loss=0.00653, val_acc=0.683, val_loss=1.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00223: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249:  25%|▉   | 249/1000 [38:16<1:46:51,  8.54s/it, lr=7.81e-6, test_acc=0.733, time=9.35, train_acc=1, train_loss=0.00726, val_acc=0.7, val_loss=1.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00249: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 275:  28%|█▋    | 275/1000 [42:17<1:46:05,  8.78s/it, lr=3.91e-6, test_acc=0.717, time=7.71, train_acc=1, train_loss=0.0123, val_acc=0.683, val_loss=2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00275: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 300:  30%|█▏  | 300/1000 [46:12<1:47:49,  9.24s/it, lr=1.95e-6, test_acc=0.733, time=10.5, train_acc=1, train_loss=0.011, val_acc=0.683, val_loss=1.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00301: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.7333\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 300.0000\n",
      "RUN NUMBER:  2\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62:   6%|▍      | 62/1000 [09:36<2:14:39,  8.61s/it, lr=0.001, test_acc=0.45, time=7.45, train_acc=0.863, train_loss=0.399, val_acc=0.5, val_loss=2.79]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00062: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88:   9%|▎  | 88/1000 [13:39<2:15:15,  8.90s/it, lr=0.0005, test_acc=0.667, time=7.76, train_acc=0.981, train_loss=0.0827, val_acc=0.55, val_loss=2.47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00088: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114:  11%| | 114/1000 [17:17<1:30:48,  6.15s/it, lr=0.00025, test_acc=0.75, time=4.92, train_acc=0.996, train_loss=0.0329, val_acc=0.583, val_loss=2.53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00114: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140:  14%|▎ | 140/1000 [20:12<1:41:00,  7.05s/it, lr=0.000125, test_acc=0.7, time=5.32, train_acc=0.994, train_loss=0.0253, val_acc=0.6, val_loss=2.81]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00140: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166:  17%|▏| 166/1000 [22:57<1:15:38,  5.44s/it, lr=6.25e-5, test_acc=0.733, time=5.05, train_acc=0.998, train_loss=0.0236, val_acc=0.633, val_loss=2.5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00166: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192:  19%|▏| 192/1000 [25:40<1:26:53,  6.45s/it, lr=3.13e-5, test_acc=0.733, time=7.21, train_acc=0.996, train_loss=0.0162, val_acc=0.65, val_loss=2.74"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00192: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 218:  22%|█    | 218/1000 [29:25<1:56:06,  8.91s/it, lr=1.56e-5, test_acc=0.733, time=6.25, train_acc=1, train_loss=0.0105, val_acc=0.65, val_loss=2.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00218: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 244:  24%|▋  | 244/1000 [33:52<2:10:24, 10.35s/it, lr=7.81e-6, test_acc=0.733, time=9.48, train_acc=1, train_loss=0.0153, val_acc=0.633, val_loss=2.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00244: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 270:  27%|█▎   | 270/1000 [37:08<1:29:29,  7.36s/it, lr=3.91e-6, test_acc=0.733, time=8.8, train_acc=1, train_loss=0.0139, val_acc=0.65, val_loss=2.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00270: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 295:  30%|▎| 295/1000 [40:03<1:35:45,  8.15s/it, lr=1.95e-6, test_acc=0.733, time=6.65, train_acc=0.998, train_loss=0.0171, val_acc=0.65, val_loss=2.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00296: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.7333\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 295.0000\n",
      "RUN NUMBER:  3\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93:   9%|▋       | 93/1000 [10:36<1:52:25,  7.44s/it, lr=0.001, test_acc=0.6, time=7.31, train_acc=0.96, train_loss=0.13, val_acc=0.517, val_loss=2.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00093: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126:  13%|▏| 126/1000 [14:21<1:25:55,  5.90s/it, lr=0.0005, test_acc=0.717, time=5.35, train_acc=0.992, train_loss=0.0207, val_acc=0.65, val_loss=1.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00126: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152:  15%|▊    | 152/1000 [17:07<1:30:47,  6.42s/it, lr=0.00025, test_acc=0.717, time=7, train_acc=1, train_loss=0.00301, val_acc=0.717, val_loss=1.36]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00152: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178:  18%|▏| 178/1000 [20:04<1:28:26,  6.46s/it, lr=0.000125, test_acc=0.717, time=6.73, train_acc=1, train_loss=0.00372, val_acc=0.717, val_loss=1.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00178: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 204:  20%|▊   | 204/1000 [22:48<1:28:44,  6.69s/it, lr=6.25e-5, test_acc=0.717, time=8.27, train_acc=1, train_loss=0.00212, val_acc=0.7, val_loss=1.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00204: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 230:  23%|▍ | 230/1000 [25:33<1:17:23,  6.03s/it, lr=3.13e-5, test_acc=0.717, time=5.45, train_acc=1, train_loss=0.00271, val_acc=0.733, val_loss=1.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00230: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 256:  26%|▌ | 256/1000 [28:05<1:19:36,  6.42s/it, lr=1.56e-5, test_acc=0.717, time=7.46, train_acc=1, train_loss=0.00105, val_acc=0.717, val_loss=1.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00256: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 282:  28%|▌ | 282/1000 [31:08<1:12:13,  6.04s/it, lr=7.81e-6, test_acc=0.717, time=5.49, train_acc=1, train_loss=0.00219, val_acc=0.733, val_loss=1.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00282: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 308:  31%|█▌   | 308/1000 [34:35<1:41:42,  8.82s/it, lr=3.91e-6, test_acc=0.717, time=9.27, train_acc=1, train_loss=0.00291, val_acc=0.7, val_loss=1.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00308: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 333:  33%|▋ | 333/1000 [37:55<1:15:57,  6.83s/it, lr=1.95e-6, test_acc=0.717, time=5.61, train_acc=1, train_loss=0.00179, val_acc=0.717, val_loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00334: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.7167\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 333.0000\n",
      "RUN NUMBER:  4\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54:   5%|▎     | 54/1000 [05:56<1:55:05,  7.30s/it, lr=0.001, test_acc=0.517, time=7.82, train_acc=0.873, train_loss=0.403, val_acc=0.5, val_loss=2.08]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00054: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90:   9%|▎  | 90/1000 [10:02<1:39:43,  6.58s/it, lr=0.0005, test_acc=0.617, time=6.74, train_acc=0.992, train_loss=0.054, val_acc=0.617, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00090: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116:  12%| | 116/1000 [13:08<1:59:27,  8.11s/it, lr=0.00025, test_acc=0.583, time=9.32, train_acc=0.983, train_loss=0.052, val_acc=0.683, val_loss=1.59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00116: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142:  14%|▏| 142/1000 [16:44<2:04:13,  8.69s/it, lr=0.000125, test_acc=0.6, time=8.42, train_acc=0.998, train_loss=0.0138, val_acc=0.633, val_loss=1.74"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00142: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168:  17%|▏| 168/1000 [19:43<1:24:18,  6.08s/it, lr=6.25e-5, test_acc=0.65, time=5.9, train_acc=0.998, train_loss=0.0123, val_acc=0.633, val_loss=1.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00168: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194:  19%|▊   | 194/1000 [22:35<1:25:42,  6.38s/it, lr=3.13e-5, test_acc=0.617, time=6.32, train_acc=1, train_loss=0.00889, val_acc=0.6, val_loss=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00194: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220:  22%|▏| 220/1000 [25:09<1:14:30,  5.73s/it, lr=1.56e-5, test_acc=0.617, time=5.76, train_acc=0.998, train_loss=0.0106, val_acc=0.6, val_loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00220: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 246:  25%|▋  | 246/1000 [27:45<1:15:09,  5.98s/it, lr=7.81e-6, test_acc=0.65, time=5.77, train_acc=1, train_loss=0.00779, val_acc=0.583, val_loss=1.81]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00246: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 272:  27%|▊  | 272/1000 [30:19<1:19:03,  6.52s/it, lr=3.91e-6, test_acc=0.65, time=5.72, train_acc=1, train_loss=0.00516, val_acc=0.617, val_loss=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00272: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 297:  30%|█▍   | 297/1000 [33:24<1:19:05,  6.75s/it, lr=1.95e-6, test_acc=0.65, time=7.76, train_acc=1, train_loss=0.00756, val_acc=0.6, val_loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00298: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.6500\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 297.0000\n",
      "RUN NUMBER:  5\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46:   5%|▍        | 46/1000 [05:50<2:22:12,  8.94s/it, lr=0.001, test_acc=0.4, time=11, train_acc=0.792, train_loss=0.57, val_acc=0.383, val_loss=2.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00046: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72:   7%|▎   | 72/1000 [09:25<2:30:30,  9.73s/it, lr=0.0005, test_acc=0.367, time=8.31, train_acc=0.95, train_loss=0.173, val_acc=0.433, val_loss=3.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00072: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98:  10%| | 98/1000 [13:22<2:04:29,  8.28s/it, lr=0.00025, test_acc=0.683, time=7.02, train_acc=0.992, train_loss=0.0655, val_acc=0.683, val_loss=2.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00098: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124:  12%|▍   | 124/1000 [17:15<2:08:32,  8.80s/it, lr=0.000125, test_acc=0.667, time=8.72, train_acc=1, train_loss=0.039, val_acc=0.65, val_loss=2.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00124: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150:  15%|▎ | 150/1000 [21:10<1:58:13,  8.34s/it, lr=6.25e-5, test_acc=0.7, time=6.26, train_acc=0.983, train_loss=0.0519, val_acc=0.65, val_loss=2.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00150: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176:  18%|▏| 176/1000 [23:57<1:27:35,  6.38s/it, lr=3.13e-5, test_acc=0.667, time=7.51, train_acc=0.996, train_loss=0.0346, val_acc=0.65, val_loss=2.14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00176: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 202:  20%|█    | 202/1000 [26:48<1:42:21,  7.70s/it, lr=1.56e-5, test_acc=0.7, time=7.23, train_acc=1, train_loss=0.0273, val_acc=0.617, val_loss=2.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00202: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 228:  23%|▉   | 228/1000 [29:48<1:16:24,  5.94s/it, lr=7.81e-6, test_acc=0.683, time=5.94, train_acc=1, train_loss=0.022, val_acc=0.633, val_loss=2.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00228: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 254:  25%|█▊     | 254/1000 [32:34<1:24:38,  6.81s/it, lr=3.91e-6, test_acc=0.683, time=7, train_acc=1, train_loss=0.0218, val_acc=0.65, val_loss=2.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00254: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279:  28%|▎| 279/1000 [35:17<1:31:11,  7.59s/it, lr=1.95e-6, test_acc=0.683, time=8.68, train_acc=0.998, train_loss=0.0294, val_acc=0.65, val_loss=2.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00280: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.6833\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 279.0000\n",
      "RUN NUMBER:  6\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47:   5%|▎     | 47/1000 [05:47<1:50:41,  6.97s/it, lr=0.001, test_acc=0.45, time=6.14, train_acc=0.821, train_loss=0.55, val_acc=0.333, val_loss=2.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00047: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73:   7%|▎    | 73/1000 [09:05<1:49:48,  7.11s/it, lr=0.0005, test_acc=0.6, time=6.56, train_acc=0.938, train_loss=0.193, val_acc=0.467, val_loss=3.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00073: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99:  10%|▏ | 99/1000 [11:49<1:35:37,  6.37s/it, lr=0.00025, test_acc=0.667, time=6.7, train_acc=0.988, train_loss=0.0602, val_acc=0.583, val_loss=2.89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00099: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125:  12%|▏| 125/1000 [14:33<1:27:59,  6.03s/it, lr=0.000125, test_acc=0.717, time=5.2, train_acc=0.996, train_loss=0.045, val_acc=0.617, val_loss=2.98"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00125: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151:  15%|▊    | 151/1000 [17:09<1:23:05,  5.87s/it, lr=6.25e-5, test_acc=0.733, time=5.3, train_acc=1, train_loss=0.031, val_acc=0.633, val_loss=3.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00151: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177:  18%|▏| 177/1000 [19:55<1:22:36,  6.02s/it, lr=3.13e-5, test_acc=0.717, time=5.51, train_acc=0.998, train_loss=0.0197, val_acc=0.617, val_loss=3.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00177: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 203:  20%|▏| 203/1000 [22:31<1:22:55,  6.24s/it, lr=1.56e-5, test_acc=0.733, time=7.03, train_acc=0.992, train_loss=0.0395, val_acc=0.633, val_loss=3.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00203: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229:  23%|█▏   | 229/1000 [25:09<1:16:07,  5.92s/it, lr=7.81e-6, test_acc=0.733, time=5.8, train_acc=1, train_loss=0.0181, val_acc=0.633, val_loss=3.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00229: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 255:  26%|▎| 255/1000 [28:16<1:44:01,  8.38s/it, lr=3.91e-6, test_acc=0.733, time=8.2, train_acc=0.996, train_loss=0.0332, val_acc=0.633, val_loss=3.18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00255: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 280:  28%|▊  | 280/1000 [31:08<1:20:03,  6.67s/it, lr=1.95e-6, test_acc=0.733, time=5.85, train_acc=1, train_loss=0.0231, val_acc=0.633, val_loss=3.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00281: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.7333\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 280.0000\n",
      "RUN NUMBER:  7\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110:  11%|▎  | 110/1000 [12:39<1:28:53,  5.99s/it, lr=0.001, test_acc=0.733, time=4.97, train_acc=0.99, train_loss=0.0218, val_acc=0.75, val_loss=1.53]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00110: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136:  14%|▏| 136/1000 [15:24<1:26:59,  6.04s/it, lr=0.0005, test_acc=0.75, time=5.53, train_acc=0.998, train_loss=0.00738, val_acc=0.783, val_loss=1.43"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00136: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162:  16%|▎ | 162/1000 [18:47<2:07:22,  9.12s/it, lr=0.00025, test_acc=0.733, time=8.89, train_acc=1, train_loss=0.00537, val_acc=0.767, val_loss=1.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00162: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188:  19%|▍ | 188/1000 [22:04<1:36:12,  7.11s/it, lr=0.000125, test_acc=0.75, time=7.76, train_acc=1, train_loss=0.00169, val_acc=0.783, val_loss=1.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00188: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 214:  21%|▏| 214/1000 [24:46<1:19:07,  6.04s/it, lr=6.25e-5, test_acc=0.733, time=5.43, train_acc=0.998, train_loss=0.00522, val_acc=0.8, val_loss=1.56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00214: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 240:  24%|▉   | 240/1000 [27:30<1:23:20,  6.58s/it, lr=3.13e-5, test_acc=0.75, time=6.89, train_acc=1, train_loss=0.00289, val_acc=0.767, val_loss=1.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00240: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 266:  27%|▌ | 266/1000 [30:21<1:36:01,  7.85s/it, lr=1.56e-5, test_acc=0.733, time=8.56, train_acc=1, train_loss=0.00139, val_acc=0.783, val_loss=1.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00266: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 292:  29%|▉  | 292/1000 [33:44<1:12:49,  6.17s/it, lr=7.81e-6, test_acc=0.75, time=5.83, train_acc=1, train_loss=0.00149, val_acc=0.783, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00292: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 318:  32%|▉  | 318/1000 [36:58<1:16:25,  6.72s/it, lr=3.91e-6, test_acc=0.733, time=7.97, train_acc=1, train_loss=0.00153, val_acc=0.75, val_loss=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00318: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 343:  34%|█  | 343/1000 [40:36<1:17:47,  7.10s/it, lr=1.95e-6, test_acc=0.733, time=8.51, train_acc=1, train_loss=0.00163, val_acc=0.767, val_loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00344: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.7333\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 343.0000\n",
      "RUN NUMBER:  8\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55:   6%|▎    | 55/1000 [07:00<1:50:37,  7.02s/it, lr=0.001, test_acc=0.55, time=6.49, train_acc=0.829, train_loss=0.493, val_acc=0.483, val_loss=1.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00055: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81:   8%|▍    | 81/1000 [10:34<1:59:23,  7.79s/it, lr=0.0005, test_acc=0.6, time=7.43, train_acc=0.931, train_loss=0.197, val_acc=0.617, val_loss=1.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00081: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107:  11%| | 107/1000 [13:55<1:53:28,  7.62s/it, lr=0.00025, test_acc=0.617, time=7.84, train_acc=0.988, train_loss=0.0623, val_acc=0.717, val_loss=1.5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00107: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133:  13%|▎ | 133/1000 [17:10<1:41:29,  7.02s/it, lr=0.000125, test_acc=0.667, time=6.63, train_acc=1, train_loss=0.0192, val_acc=0.683, val_loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00133: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159:  16%|▏| 159/1000 [20:12<1:43:18,  7.37s/it, lr=6.25e-5, test_acc=0.6, time=7.97, train_acc=0.998, train_loss=0.0241, val_acc=0.633, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00159: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185:  18%|▉    | 185/1000 [23:12<1:30:53,  6.69s/it, lr=3.13e-5, test_acc=0.6, time=7.22, train_acc=1, train_loss=0.0184, val_acc=0.667, val_loss=1.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00185: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 211:  21%|▏| 211/1000 [26:27<1:28:18,  6.72s/it, lr=1.56e-5, test_acc=0.617, time=6.35, train_acc=0.998, train_loss=0.0189, val_acc=0.633, val_loss=1.6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00211: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 237:  24%|█▏   | 237/1000 [29:42<1:42:28,  8.06s/it, lr=7.81e-6, test_acc=0.617, time=6.27, train_acc=1, train_loss=0.0167, val_acc=0.65, val_loss=1.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00237: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 263:  26%|█   | 263/1000 [32:59<1:35:09,  7.75s/it, lr=3.91e-6, test_acc=0.617, time=8.41, train_acc=1, train_loss=0.0156, val_acc=0.65, val_loss=1.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00263: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 288:  29%|▎| 288/1000 [36:02<1:29:07,  7.51s/it, lr=1.95e-6, test_acc=0.617, time=8.38, train_acc=0.998, train_loss=0.0205, val_acc=0.633, val_loss=1.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00289: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.6167\n",
      "Train Accuracy [LAST EPOCH]: 0.9979\n",
      "Convergence Time (Epochs): 288.0000\n",
      "RUN NUMBER:  9\n",
      "Training Graphs:  480\n",
      "Validation Graphs:  60\n",
      "Test Graphs:  60\n",
      "Number of Classes:  6\n",
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68:   7%|▍      | 68/1000 [08:33<1:41:07,  6.51s/it, lr=0.001, test_acc=0.517, time=7.27, train_acc=0.9, train_loss=0.307, val_acc=0.55, val_loss=2.03]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00068: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100:  10%|▏ | 100/1000 [11:53<1:29:05,  5.94s/it, lr=0.0005, test_acc=0.617, time=6.1, train_acc=0.992, train_loss=0.0435, val_acc=0.65, val_loss=1.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00100: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127:  13%|▍  | 127/1000 [14:42<1:23:09,  5.71s/it, lr=0.00025, test_acc=0.583, time=5.35, train_acc=1, train_loss=0.0115, val_acc=0.683, val_loss=1.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00127: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153:  15%|▏| 153/1000 [17:33<1:33:55,  6.65s/it, lr=0.000125, test_acc=0.6, time=6.18, train_acc=0.998, train_loss=0.0109, val_acc=0.683, val_loss=1.61"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00153: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179:  18%|▉    | 179/1000 [20:19<1:28:31,  6.47s/it, lr=6.25e-5, test_acc=0.617, time=5.8, train_acc=1, train_loss=0.00706, val_acc=0.7, val_loss=1.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00179: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 205:  20%|█▏    | 205/1000 [23:10<1:20:30,  6.08s/it, lr=3.13e-5, test_acc=0.6, time=6.29, train_acc=1, train_loss=0.00703, val_acc=0.7, val_loss=1.56]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00205: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 257:  26%|█   | 257/1000 [28:26<1:16:56,  6.21s/it, lr=7.81e-6, test_acc=0.6, time=6.08, train_acc=1, train_loss=0.00563, val_acc=0.733, val_loss=1.56]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00257: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 283:  28%|▎| 283/1000 [31:10<1:12:03,  6.03s/it, lr=3.91e-6, test_acc=0.6, time=6.3, train_acc=0.998, train_loss=0.00931, val_acc=0.733, val_loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00283: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 308:  31%|▎| 308/1000 [33:53<1:16:08,  6.60s/it, lr=1.95e-6, test_acc=0.6, time=6.66, train_acc=0.998, train_loss=0.00828, val_acc=0.733, val_loss=1.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00309: reducing learning rate of group 0 to 9.7656e-07.\n",
      "\n",
      "!! LR EQUAL TO MIN LR SET.\n",
      "Test Accuracy [LAST EPOCH]: 0.6000\n",
      "Train Accuracy [LAST EPOCH]: 1.0000\n",
      "Convergence Time (Epochs): 308.0000\n",
      "TOTAL TIME TAKEN: 6.2716hrs\n",
      "AVG TIME PER EPOCH: 7.3937s\n",
      "AVG CONVERGENCE Time (Epochs): 303.7000\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULTS\n",
      "\n",
      "TEST ACCURACY averaged: 68.0000 with s.d. 5.5176\n",
      "\n",
      "All splits Test Accuracies:\n",
      " [0.6, 0.7333333333333333, 0.7333333333333333, 0.7166666666666667, 0.65, 0.6833333333333333, 0.7333333333333333, 0.7333333333333333, 0.6166666666666667, 0.6]\n",
      "\n",
      "\n",
      "\n",
      "FINAL RESULTS\n",
      "\n",
      "TRAIN ACCURACY averaged: 99.9792 with s.d. 0.0625\n",
      "\n",
      "All splits Train Accuracies:\n",
      " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9979166666666667, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def main(notebook_mode=False,config=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        USER CONTROLS\n",
    "    \"\"\"\n",
    "    \n",
    "    # terminal mode\n",
    "    if notebook_mode==False:\n",
    "        \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--config', help=\"Please give a config.json file with training/model/data/param details\")\n",
    "        parser.add_argument('--gpu_id', help=\"Please give a value for gpu id\")\n",
    "        parser.add_argument('--model', help=\"Please give a value for model name\")\n",
    "        parser.add_argument('--dataset', help=\"Please give a value for dataset name\")\n",
    "        parser.add_argument('--out_dir', help=\"Please give a value for out_dir\")\n",
    "        parser.add_argument('--seed', help=\"Please give a value for seed\")\n",
    "        parser.add_argument('--epochs', help=\"Please give a value for epochs\")\n",
    "        parser.add_argument('--batch_size', help=\"Please give a value for batch_size\")\n",
    "        parser.add_argument('--init_lr', help=\"Please give a value for init_lr\")\n",
    "        parser.add_argument('--lr_reduce_factor', help=\"Please give a value for lr_reduce_factor\")\n",
    "        parser.add_argument('--lr_schedule_patience', help=\"Please give a value for lr_schedule_patience\")\n",
    "        parser.add_argument('--min_lr', help=\"Please give a value for min_lr\")\n",
    "        parser.add_argument('--weight_decay', help=\"Please give a value for weight_decay\")\n",
    "        parser.add_argument('--print_epoch_interval', help=\"Please give a value for print_epoch_interval\")    \n",
    "        parser.add_argument('--L', help=\"Please give a value for L\")\n",
    "        parser.add_argument('--hidden_dim', help=\"Please give a value for hidden_dim\")\n",
    "        parser.add_argument('--out_dim', help=\"Please give a value for out_dim\")\n",
    "        parser.add_argument('--residual', help=\"Please give a value for residual\")\n",
    "        parser.add_argument('--edge_feat', help=\"Please give a value for edge_feat\")\n",
    "        parser.add_argument('--readout', help=\"Please give a value for readout\")\n",
    "        parser.add_argument('--kernel', help=\"Please give a value for kernel\")\n",
    "        parser.add_argument('--n_heads', help=\"Please give a value for n_heads\")\n",
    "        parser.add_argument('--gated', help=\"Please give a value for gated\")\n",
    "        parser.add_argument('--in_feat_dropout', help=\"Please give a value for in_feat_dropout\")\n",
    "        parser.add_argument('--dropout', help=\"Please give a value for dropout\")\n",
    "        parser.add_argument('--layer_norm', help=\"Please give a value for layer_norm\")\n",
    "        parser.add_argument('--batch_norm', help=\"Please give a value for batch_norm\")\n",
    "        parser.add_argument('--sage_aggregator', help=\"Please give a value for sage_aggregator\")\n",
    "        parser.add_argument('--data_mode', help=\"Please give a value for data_mode\")\n",
    "        parser.add_argument('--num_pool', help=\"Please give a value for num_pool\")\n",
    "        parser.add_argument('--gnn_per_block', help=\"Please give a value for gnn_per_block\")\n",
    "        parser.add_argument('--embedding_dim', help=\"Please give a value for embedding_dim\")\n",
    "        parser.add_argument('--pool_ratio', help=\"Please give a value for pool_ratio\")\n",
    "        parser.add_argument('--linkpred', help=\"Please give a value for linkpred\")\n",
    "        parser.add_argument('--cat', help=\"Please give a value for cat\")\n",
    "        parser.add_argument('--self_loop', help=\"Please give a value for self_loop\")\n",
    "        parser.add_argument('--max_time', help=\"Please give a value for max_time\")\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        with open(args.config) as f:\n",
    "            config = json.load(f)\n",
    "            \n",
    "\n",
    "        # device\n",
    "        if args.gpu_id is not None:\n",
    "            config['gpu']['id'] = int(args.gpu_id)\n",
    "            config['gpu']['use'] = True\n",
    "        device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
    "\n",
    "        # model, dataset, out_dir\n",
    "        if args.model is not None:\n",
    "            MODEL_NAME = args.model\n",
    "        else:\n",
    "            MODEL_NAME = config['model']\n",
    "        if args.dataset is not None:\n",
    "            DATASET_NAME = args.dataset\n",
    "        else:\n",
    "            DATASET_NAME = config['dataset']\n",
    "        dataset = LoadData(DATASET_NAME)\n",
    "        if args.out_dir is not None:\n",
    "            out_dir = args.out_dir\n",
    "        else:\n",
    "            out_dir = config['out_dir']\n",
    "\n",
    "        # parameters\n",
    "        params = config['params']\n",
    "        if args.seed is not None:\n",
    "            params['seed'] = int(args.seed)\n",
    "        if args.epochs is not None:\n",
    "            params['epochs'] = int(args.epochs)\n",
    "        if args.batch_size is not None:\n",
    "            params['batch_size'] = int(args.batch_size)\n",
    "        if args.init_lr is not None:\n",
    "            params['init_lr'] = float(args.init_lr)\n",
    "        if args.lr_reduce_factor is not None:\n",
    "            params['lr_reduce_factor'] = float(args.lr_reduce_factor)\n",
    "        if args.lr_schedule_patience is not None:\n",
    "            params['lr_schedule_patience'] = int(args.lr_schedule_patience)\n",
    "        if args.min_lr is not None:\n",
    "            params['min_lr'] = float(args.min_lr)\n",
    "        if args.weight_decay is not None:\n",
    "            params['weight_decay'] = float(args.weight_decay)\n",
    "        if args.print_epoch_interval is not None:\n",
    "            params['print_epoch_interval'] = int(args.print_epoch_interval)\n",
    "        if args.max_time is not None:\n",
    "            params['max_time'] = float(args.max_time)\n",
    "\n",
    "        # network parameters\n",
    "        net_params = config['net_params']\n",
    "        net_params['device'] = device\n",
    "        net_params['gpu_id'] = config['gpu']['id']\n",
    "        net_params['batch_size'] = params['batch_size']\n",
    "        if args.L is not None:\n",
    "            net_params['L'] = int(args.L)\n",
    "        if args.hidden_dim is not None:\n",
    "            net_params['hidden_dim'] = int(args.hidden_dim)\n",
    "        if args.out_dim is not None:\n",
    "            net_params['out_dim'] = int(args.out_dim)   \n",
    "        if args.residual is not None:\n",
    "            net_params['residual'] = True if args.residual=='True' else False\n",
    "        if args.edge_feat is not None:\n",
    "            net_params['edge_feat'] = True if args.edge_feat=='True' else False\n",
    "        if args.readout is not None:\n",
    "            net_params['readout'] = args.readout\n",
    "        if args.kernel is not None:\n",
    "            net_params['kernel'] = int(args.kernel)\n",
    "        if args.n_heads is not None:\n",
    "            net_params['n_heads'] = int(args.n_heads)\n",
    "        if args.gated is not None:\n",
    "            net_params['gated'] = True if args.gated=='True' else False\n",
    "        if args.in_feat_dropout is not None:\n",
    "            net_params['in_feat_dropout'] = float(args.in_feat_dropout)\n",
    "        if args.dropout is not None:\n",
    "            net_params['dropout'] = float(args.dropout)\n",
    "        if args.layer_norm is not None:\n",
    "            net_params['layer_norm'] = True if args.layer_norm=='True' else False\n",
    "        if args.batch_norm is not None:\n",
    "            net_params['batch_norm'] = True if args.batch_norm=='True' else False\n",
    "        if args.sage_aggregator is not None:\n",
    "            net_params['sage_aggregator'] = args.sage_aggregator\n",
    "        if args.data_mode is not None:\n",
    "            net_params['data_mode'] = args.data_mode\n",
    "        if args.num_pool is not None:\n",
    "            net_params['num_pool'] = int(args.num_pool)\n",
    "        if args.gnn_per_block is not None:\n",
    "            net_params['gnn_per_block'] = int(args.gnn_per_block)\n",
    "        if args.embedding_dim is not None:\n",
    "            net_params['embedding_dim'] = int(args.embedding_dim)\n",
    "        if args.pool_ratio is not None:\n",
    "            net_params['pool_ratio'] = float(args.pool_ratio)\n",
    "        if args.linkpred is not None:\n",
    "            net_params['linkpred'] = True if args.linkpred=='True' else False\n",
    "        if args.cat is not None:\n",
    "            net_params['cat'] = True if args.cat=='True' else False\n",
    "        if args.self_loop is not None:\n",
    "            net_params['self_loop'] = True if args.self_loop=='True' else False\n",
    "\n",
    "            \n",
    "    # notebook mode\n",
    "    if notebook_mode:\n",
    "        \n",
    "        # parameters\n",
    "        params = config['params']\n",
    "        \n",
    "        # dataset\n",
    "        DATASET_NAME = config['dataset']\n",
    "        dataset = LoadData(DATASET_NAME)\n",
    "        \n",
    "        # device\n",
    "        device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
    "        out_dir = config['out_dir']\n",
    "        \n",
    "        # GNN model\n",
    "        MODEL_NAME = config['model']\n",
    "        \n",
    "        # network parameters\n",
    "        net_params = config['net_params']\n",
    "        net_params['device'] = device\n",
    "        net_params['gpu_id'] = config['gpu']['id']\n",
    "        net_params['batch_size'] = params['batch_size']\n",
    "      \n",
    "    \n",
    "    # TUs\n",
    "    net_params['in_dim'] = dataset.all.graph_lists[0].ndata['feat'][0].shape[0]\n",
    "    num_classes = len(np.unique(dataset.all.graph_labels))\n",
    "    net_params['n_classes'] = num_classes\n",
    "    \n",
    "    if MODEL_NAME == 'DiffPool':\n",
    "        # calculate assignment dimension: pool_ratio * largest graph's maximum\n",
    "        # number of nodes  in the dataset\n",
    "        num_nodes = [dataset.all[i][0].number_of_nodes() for i in range(len(dataset.all))]\n",
    "        max_num_node = max(num_nodes)\n",
    "        net_params['assign_dim'] = int(max_num_node * net_params['pool_ratio']) * net_params['batch_size']\n",
    "        \n",
    "    if MODEL_NAME == 'RingGNN':\n",
    "        num_nodes = [dataset.all[i][0].number_of_nodes() for i in range(len(dataset.all))]\n",
    "        net_params['avg_node_num'] = int(np.ceil(np.mean(num_nodes)))\n",
    "    \n",
    "    root_log_dir = out_dir + 'logs/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "    root_ckpt_dir = out_dir + 'checkpoints/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "    write_file_name = out_dir + 'results/result_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "    write_config_file = out_dir + 'configs/config_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
    "    dirs = root_log_dir, root_ckpt_dir, write_file_name, write_config_file\n",
    "\n",
    "    if not os.path.exists(out_dir + 'results'):\n",
    "        os.makedirs(out_dir + 'results')\n",
    "        \n",
    "    if not os.path.exists(out_dir + 'configs'):\n",
    "        os.makedirs(out_dir + 'configs')\n",
    "\n",
    "    net_params['total_param'] = view_model_param(MODEL_NAME, net_params)\n",
    "    train_val_pipeline(MODEL_NAME, DATASET_NAME, params, net_params, dirs)\n",
    "\n",
    "if notebook_mode==True:\n",
    "    \n",
    "    config = {}\n",
    "    # gpu config\n",
    "    gpu = {}\n",
    "    gpu['use'] = use_gpu\n",
    "    gpu['id'] = gpu_id\n",
    "    config['gpu'] = gpu\n",
    "    # GNN model, dataset, out_dir\n",
    "    config['model'] = MODEL_NAME\n",
    "    config['dataset'] = DATASET_NAME\n",
    "    config['out_dir'] = out_dir\n",
    "    # parameters\n",
    "    params = {}\n",
    "    params['seed'] = seed\n",
    "    params['epochs'] = epochs\n",
    "    params['batch_size'] = batch_size\n",
    "    params['init_lr'] = init_lr\n",
    "    params['lr_reduce_factor'] = lr_reduce_factor \n",
    "    params['lr_schedule_patience'] = lr_schedule_patience\n",
    "    params['min_lr'] = min_lr\n",
    "    params['weight_decay'] = weight_decay\n",
    "    params['print_epoch_interval'] = 5\n",
    "    params['max_time'] = max_time\n",
    "    config['params'] = params\n",
    "    # network parameters\n",
    "    config['net_params'] = net_params\n",
    "    \n",
    "    # convert to .py format\n",
    "    from utils.cleaner_main import *\n",
    "    cleaner_main('main_TUs_graph_classification')\n",
    "    \n",
    "    main(True,config)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
